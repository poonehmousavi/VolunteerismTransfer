{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, cohen_kappa_score, precision_score, recall_score, \\\n",
    "    precision_recall_curve\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.semi_supervised import LabelSpreading, LabelPropagation\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.downloader import base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your output and input Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path=\"/home/VolunteerismTransfe/out/model/fasttext/weaksupervison/\"\n",
    "base_path=\"/home/VolunteerismTransfer/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "We have 5 Different Inputs:\n",
    "    Labeled data ,\n",
    "    Labeled data + NGO accounts(labeled as  \"volunteer\"),\n",
    "    Labeled data + NGO accounts(labeled by label prop ),\n",
    "    Labeled data + random Data(labeled by label prop),\n",
    "    Labeled data + NGO (labeled by label prop) + random Data(labeled by label prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(base_path+'data/FT_Labeled.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get hierarchical Event Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_weight(event_type, target):\n",
    "\n",
    "    if event_type == target:\n",
    "        return 10\n",
    "    elif get_sample_category(event_type) == get_sample_category(target):\n",
    "        return 6\n",
    "    elif get_sample_category(event_type)=='general':\n",
    "        return 1\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_category(event_type):\n",
    "    if 'earthquake' in event_type or \"hurricane/typhoon/cyclone/tornado\" in event_type or \"flood\" in event_type or \"wildfire/bushfire\" in event_type or \"outbreak\" in event_type:\n",
    "        return 'natural'\n",
    "    elif \"bombing\" in event_type or \"shooting\" in event_type or \"explosion\" in event_type or \"collapse\" in event_type:\n",
    "        return \"manmade\"\n",
    "    else:\n",
    "        return \"general\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SVM Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train,Y_train,sample_weight=None):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for index, value in X_train.items():\n",
    "        x.append(value)\n",
    "        y.append(Y_train[index])\n",
    "    pipeline_sgd = Pipeline([\n",
    "    ('nb', SGDClassifier(loss='hinge')),\n",
    "    ])\n",
    "    model=pipeline_sgd.fit(x, y,nb__sample_weight=sample_weight)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify how to split training and test data by chooisng value from ['eventid','event_type']\n",
    "groupby_col='eventid'\n",
    "\n",
    "# Specify Rebalancing strategy from ['none,'up','down','up-with-same-eventtype','up-with-same-eventCategory']\n",
    "sampling_strategy='up' \n",
    "\n",
    "#Specify if to use up-weighting samples from the same event type as the held-out event or not\n",
    "up_weighting=True\n",
    "\n",
    "events=data.groupby([groupby_col]).groups.keys()\n",
    "result=pd.DataFrame(columns=[groupby_col,'src','precision', 'recall', 'f1_score'])\n",
    "skip=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in tqdm(events):\n",
    "    if event == 'general':\n",
    "        continue\n",
    "    training=data[data[groupby_col] != event]\n",
    "    test = data[data[groupby_col] == event]\n",
    "\n",
    "    if up_weighting == True:\n",
    "        training['sample_weight'] = 100 * np.abs(np.random.randn(training.shape[0]))\n",
    "        # same_event_data = training[training.event_type == test.iloc[0].event_type]\n",
    "        training['sample_weight'] = np.where(training['event_type'] ==  test.iloc[0].event_type,\n",
    "                                training['sample_weight'] * 10,\n",
    "                                training['sample_weight'])\n",
    "\n",
    "    vol = training.loc[training.label == 1]\n",
    "    non_vol = training.loc[training.label == 0]\n",
    "\n",
    "    # Equally sample 'pos' and 'neg' with replacement and concatenate into a dataframe.\n",
    "    if sampling_strategy == 'up':\n",
    "        training = non_vol.append(vol.sample(n=len(non_vol), replace=True), ignore_index=True)\n",
    "\n",
    "    elif sampling_strategy == 'down':\n",
    "        training = vol.append(non_vol.sample(n=len(vol), replace=True), ignore_index=True)\n",
    "\n",
    "    elif sampling_strategy== \"up-with-same-eventtype\":\n",
    "        training['sample_weight'] = 1\n",
    "        training['sample_weight'] = np.where(training['event_type'] == test.iloc[0].event_type,\n",
    "                                                 training['sample_weight'] * 10,\n",
    "                                                 training['sample_weight'])\n",
    "        vol = training.loc[training.label == 1]\n",
    "        non_vol = training.loc[training.label == 0]\n",
    "        training = non_vol.append(vol.sample(n=len(non_vol),weights='sample_weight', replace=True), ignore_index=True)\n",
    "\n",
    "    elif sampling_strategy== \"up-with-same-eventCategory\":\n",
    "        training['sample_weight'] = [get_sample_weight(x,test.iloc[0].event_type) for x in training['event_type']]\n",
    "        vol = training.loc[training.label == 1]\n",
    "        non_vol = training.loc[training.label == 0]\n",
    "        training = non_vol.append(vol.sample(n=len(non_vol),weights='sample_weight', replace=True), ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    if training.shape[0]== 0:\n",
    "        print(event)\n",
    "        recall = 0\n",
    "        precision = 0\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        X_train =training['ft_features']\n",
    "        X_test = test['ft_features']\n",
    "        y_train = training['label']\n",
    "        y_test = test['label']\n",
    "        if up_weighting== True:\n",
    "            model = train_model(X_train, y_train,sample_weight=training['sample_weight'])\n",
    "        else:\n",
    "            model = train_model(X_train,y_train)\n",
    "\n",
    "\n",
    "        x=[]\n",
    "        y=[]\n",
    "        for index, value in X_test.items():\n",
    "            x.append(value)\n",
    "        y_predict = model.predict(x)\n",
    "        recall =  recall_score(y_test, y_predict)\n",
    "        precision = precision_score(y_test, y_predict)\n",
    "        # roc = roc_auc_score(y_test, y_predict)\n",
    "        from sklearn.metrics import f1_score\n",
    "        f1_score=f1_score(y_test, y_predict)\n",
    "    result = result.append({groupby_col: event,'src': test.iloc[0].src, 'precision': precision, 'recall': recall, 'f1_score': f1_score}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Result with proper filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_weight_label='_upweight' if up_weighting== True else \"\n",
    "fileName=\"labeled + NGO _\"\n",
    "filepath=output_path+fileName+groupby_col+\"_sampling_strategy-\"+sampling_strategy+up_weight_label\n",
    "print(skip)\n",
    "result.to_csv(filepath+\".csv\")\n",
    "# result.to_json(filepath+\".json\", orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
